{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from itertools import combinations\n",
    "from spacy import displacy\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "\n",
    "import en_core_web_lg\n",
    "import phonetics\n",
    "import warnings\n",
    "import inflect\n",
    "import pyphen\n",
    "import pickle\n",
    "import string\n",
    "import random\n",
    "import spacy\n",
    "import nltk\n",
    "import math\n",
    "import sys\n",
    "import csv\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nicknames():\n",
    "    \n",
    "    \"\"\" Returns a dictionairy of nicknames per artist, based on Wikipedia \"\"\"\n",
    "\n",
    "    return {\"JAY-Z\":[\"Jay-Z\",\"Jay\",\"Hova\",\"HOV\",\"hov\",\"Hov\",\"Jigga\",\"Shawn Carter\",\"Shawn\",\"Carter\"],\n",
    "    \"Eminem\": [\"Eminem\",\"Marshall Mathers\",\"Marshall\",\"Mathers\",\"Slim Shady\",\"Slim\",\"Shady\"],\n",
    "    \"Future\": [\"Future\",\"Nayvadius Wilburn\",\"Neyvadius\",\"Wiburn\",\"Meathead\",\"Caeser Lee\",\"Ceaser\",\"Lee\"],\n",
    "    \"Ice Cube\": [\"Ice Cube\",\"Ice\",\"Cube\",\"O'Shea Jackson\",\"O'Shea\",\"Jackson\"],\n",
    "    \"Lil’ Kim\": [\"Lil’ Kim\",\"Lil’\",\"Kim\",\"Kimberley Jones\",\"Kimberley\",\"Jones\",\"Queen Bee\",\"Queen\",\"Bee\", \"Lil'\",\"Lil' Kim\",\"own_nameme\", \"own_name own_name\"],\n",
    "    \"Machine Gun Kelly\": [\"Machine Gun Kelly\",\"Machine Gun\",\"Gun Kelly\",\"Kelly\",\"Kells\",\"Richard Baker\",\"Richard\",\"Baker\",\"MGK\"],\n",
    "    \"Nas\": [\"Nasty Nas\",\"Nasty\",\"Nas\",\"Escobar\", \"Jones\"],\n",
    "    \"Nicki Minaj\": [\"Nicki Minaj\",\"Nicki\",\"Minaj\",\"Onika Maraj\",\"Onika\",\"Maraj\"],\n",
    "    \"50 Cent\": [\"50 Cent\",\"Fifty Cent\",\"fifty cent\",\"fifty\",\"fiftycent\",\"50\",\"Cent\",\"Ferrari F-50\",\"Ferrari\",\"F-50\",\"Curtis Jackson\",\"Curtis\",\"Jackson\"],\n",
    "    \"2Pac\": [\"2Pac\",\"twopac\",\"Tupac Shakur\",\"Tupac\",\"Shakur\",\"Makaveli\",\"MC New York\", \"Pac\"],\n",
    "    \"Lil Wayne\": [\"Lil Wayne\",\"Wayne\",\"Tunechi\",\"Weezy F. Baby\", \"Weezy\",\"President Carter\",\"Dwayne Carter\",\"Dwayne\",\"Carter\"],\n",
    "    \"Snoop Dogg\": [\"Snoop Dogg\",\"Snoop\",\"Doggy\",\"Dogg\",\"DJ Snoopadelic\",\"Snoopadelic\",\"Niggarachi\",\"Snoopzilla\",\"Nemo Hoes\",\"Nemo\"],\n",
    "    \"Damian Marley\": [\"Damian Marley\",\"Damian\",\"Robert\",\"Nesta\",\"Jr. Gong\",\"Jr Gong\",\"Junior Gong\",\"Gong\",\"Junior\",\"Jr.\"],\n",
    "    \"Kanye West\": [\"Kanye West\",\"Kanye\",\"West\",\"Yeezy\",\"\\bYe\\b\", \"Omari\"],\n",
    "    \"Cardi B\": ['Cardi B','Cardi','\\bB\\b','Belcalis','Marlenis','Alamanzar'],\n",
    "    \"MC Lyte\": ['MC Lyte','Lyte','Lana','Michelle','Moorer'],\n",
    "    \"Missy Elliott\": ['Missy Elliot','Missy','Elliot','Misdemeanor','Melissa','Arnette'],\n",
    "    \"Iggy Azalea\": ['Iggy Azalea','Iggy','Azalea','Amethyst','Amelia','Kelly'],\n",
    "    \"Queen Latifah\": ['Queen Latifah','Queen','Latifah','Dana','Elaine','Owens']\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell functions are implemented to create (bleached) representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def create_frequency_representation(lyrics):\n",
    "    \n",
    "def create_phonetic_representation(lyrics):\n",
    "    to_phonetics = nltk.corpus.cmudict.dict()\n",
    "    phonetics_repr = ''\n",
    "    lyrics = lyrics.lower()\n",
    "    lyrics = re.sub(\"' \",\" \",lyrics) # to convert words as runnin' to runnin\n",
    "    lyrics = re.sub(\"\\-\",\" \",lyrics) # convert words a four-door to four door\n",
    "    for word in lyrics.lower().split():\n",
    "        try:\n",
    "            phonetics_repr += \"\".join(to_phonetics[word][0]) + ' '\n",
    "        except:\n",
    "            pass\n",
    "    return phonetics_repr.rstrip()\n",
    "    \n",
    "    \n",
    "def create_soundex_representation(lyrics):\n",
    "    soundex_repr = ''\n",
    "    for word in lyrics.split():\n",
    "        try:\n",
    "            soundex_repr += phonetics.soundex(word) + ' '\n",
    "        except:\n",
    "            word = re.sub(\"'\",\"\",word)\n",
    "            words = re.sub(\"\\-\", \" \",word)\n",
    "            for word in words.split():\n",
    "                try:\n",
    "                    soundex_repr += phonetics.soundex(word) + ' '\n",
    "                except:\n",
    "                    pass\n",
    "    return soundex_repr.rstrip()\n",
    "\n",
    "def create_metaphone_representation(lyrics):\n",
    "    metaphone_repr = ''\n",
    "    for word in lyrics.split():\n",
    "        try:\n",
    "            metaphone_repr += phonetics.metaphone(word) + ' '\n",
    "        except:\n",
    "            print(word)\n",
    "    return metaphone_repr.rstrip()\n",
    "\n",
    "\n",
    "def create_frequency_representation(lyrics,c_all_words):\n",
    "    return ' '.join([str(int(c_all_words[word]/20)) for word in lyrics.split()])\n",
    "\n",
    "def create_length_representation(lyrics):\n",
    "    \n",
    "    \"\"\" Converts words to their length, e.g.: Hello PC --> 05 02 \"\"\"\n",
    "    \n",
    "    length_repr = ''\n",
    "    for sentence in lyrics.split('\\n'):\n",
    "        sentence_repr = ''\n",
    "        for word in sentence.split():\n",
    "            sentence_repr += '0' + str(len(word)) + ' '\n",
    "        length_repr += sentence_repr.rstrip() + '\\n' # add newline to preserve line structure\n",
    "    \n",
    "    return length_repr.rstrip()\n",
    "\n",
    "def create_punctC_representation(lyrics):\n",
    "    \n",
    "    \"\"\" Creates a representation in which punctuation is preserved \"\"\"\n",
    "    \n",
    "    punctC_repr = \"\"\n",
    "    for sentence in lyrics.split('\\n'):\n",
    "        sentence_repr = ''\n",
    "        for word in sentence.split():\n",
    "            punctC = \"\"\n",
    "            for char in word:\n",
    "                if char not in string.punctuation:\n",
    "                    punctC += 'W'\n",
    "                else:\n",
    "                    punctC += char\n",
    "            punctC = re.sub(\"W+\", \"W\", punctC) + ' '\n",
    "            sentence_repr += punctC\n",
    "        punctC_repr += sentence_repr.rstrip() + '\\n'\n",
    "        \n",
    "    return punctC_repr.rstrip()\n",
    "\n",
    "def create_shape_representation(lyrics):\n",
    "    \n",
    "    \"\"\" Creates a representation which is based on capitality of letters, and digits\"\"\"\n",
    "    \n",
    "    shape_repr = ''\n",
    "    for sentence in lyrics.split('\\n'):\n",
    "        sentence_repr = ''\n",
    "        for word in sentence.split():\n",
    "            shape = ''\n",
    "            for char in word:\n",
    "                if char.isupper():\n",
    "                    shape += 'U'\n",
    "                elif char.islower():\n",
    "                    shape += 'L'\n",
    "                elif char.isdigit():\n",
    "                    shape += 'D'\n",
    "                else:\n",
    "                    shape += 'X'\n",
    "            for letter in 'ULDX':\n",
    "                shape = diminish_duplicate_letters(shape,letter)\n",
    "            sentence_repr += shape + ' '\n",
    "        shape_repr += sentence_repr.rstrip() + '\\n'\n",
    "    return shape_repr.rstrip()\n",
    "                \n",
    "def diminish_duplicate_letters(chars,char): # converts a 3 or more idental consecutive letters to 2\n",
    "    return re.sub(char +\"{3,}\",char+char,chars)\n",
    "\n",
    "def create_vowel_representation(lyrics):\n",
    "    \n",
    "    \"\"\" Create a representation based on vowels \"\"\"\n",
    "    \n",
    "    vowel_representations = ''\n",
    "    for sentence in lyrics.split('\\n'):\n",
    "        sentence_repr = ''\n",
    "        for word in sentence.split():\n",
    "            vowel_repr = ''\n",
    "            for char in word:\n",
    "                if char.lower() in 'aeiou':\n",
    "                    vowel_repr += 'V'\n",
    "                elif char.lower() in 'bcdfghjklmnpqrstvwxyz':\n",
    "                    vowel_repr += 'C'\n",
    "                else:\n",
    "                    vowel_repr += 'O'\n",
    "            sentence_repr += vowel_repr + ' '\n",
    "        vowel_representations += sentence_repr.rstrip() + '\\n'\n",
    "    return vowel_representations.rstrip()\n",
    "\n",
    "def create_alliteration_representation(lyrics):\n",
    "    first_letters = [word[0] for word in lyrics.split()]\n",
    "    return \"\".join(first_letters)  \n",
    "\n",
    "def create_syllable_representation(lyrics):\n",
    "    lyrics.translate(str.maketrans('', '', string.punctuation)) # source: https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string\n",
    "    to_syllables = pyphen.Pyphen(lang='en')\n",
    "    syllable_representation = ''\n",
    "    for sentence in lyrics.split('\\n'):\n",
    "        words = sentence.split()\n",
    "        for word in words:\n",
    "            syllables = to_syllables.inserted(word)\n",
    "            syllable_representation += re.sub(\"\\-\", \" \", syllables) + ' '\n",
    "        syllable_representation += '\\n'\n",
    "    return syllable_representation.rstrip()\n",
    "\n",
    "def create_NER_representation(lyrics, nlp):\n",
    "    \n",
    "    \"\"\" Creates a representation based on Named Entity Recognition\"\"\"\n",
    "    \n",
    "    NER_repr = ''\n",
    "    for sentence in lyrics.split('\\n'):\n",
    "        NER = [(X.text,X.label_) for X in nlp(sentence).ents]\n",
    "        for word in sentence.split():\n",
    "            added_NER = False\n",
    "            for tupl in NER:\n",
    "                if word == tupl[0]:\n",
    "                    NER_repr += tupl[1]\n",
    "                    added_NER = True\n",
    "            if added_NER == False:\n",
    "                NER_repr += word\n",
    "            NER_repr += ' '\n",
    "        NER_repr.rstrip()\n",
    "        NER_repr += '\\n'\n",
    "            \n",
    "    return NER_repr.rstrip()\n",
    "\n",
    "def create_POS_representation(lyrics):\n",
    "    \n",
    "    \"\"\" Creates a representation based on POS tagging \"\"\"\n",
    "    \n",
    "    tokens = nltk.word_tokenize(lyrics)\n",
    "    pos_tags = [output[1] for output in nltk.pos_tag(tokens)]\n",
    "    return ' '.join(pos_tags)\n",
    "\n",
    "def number_to_word(number): # converts a number to its word representation, e.g. 50 to fifty\n",
    "    return inflect.engine().number_to_words(number.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = en_core_web_lg.load()\n",
    "#create_NER_representation('I am John\\nNineteen twenty-one is what I represent',nlp)\n",
    "create_phonetic_representation('5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_lyrics(data):\n",
    "    \n",
    "    \"\"\" Returns a preprocessed x \"\"\"\n",
    "    \n",
    "    inflect_engine = inflect.engine()\n",
    "    nicknames = get_nicknames()\n",
    "    filtered_x, length_repr, punctC_repr, shape_repr, vowel_repr, alliteration_repr, ner_repr, pos_repr = [],[],[],[],[],[],[],[]\n",
    "    syllable_repr = []\n",
    "    print(\"Total instances to preprocess: {}\".format(len(data)))\n",
    "    i = 0 # to track where the program is\n",
    "    #nlp = en_core_web_lg.load()\n",
    "    new_data = []\n",
    "\n",
    "    for dictio in data:\n",
    "        lyrics = dictio['lyrics']\n",
    "        artist = dictio['artist']\n",
    "        lyrics = re.sub(\"\\[.*\\]\", \"\", lyrics) # removes info like [Intro: Eminem]\n",
    "        lyrics = re.sub(\"\\*.*?\\*\", \"\", lyrics) # text between *..* usually announces something\n",
    "        lyrics = re.sub(\"[wW]\\/\",\"\", lyrics)\n",
    "        lyrics = re.sub(\"[Cc]horus\",\"\", lyrics)\n",
    "        lyrics = re.sub(\"[Vv]erse\",\"\",lyrics)\n",
    "        lyrics = re.sub(\"[xX][1-9]\",\"\",lyrics)\n",
    "        lyrics = re.sub(\"\\n+\",\"\\n\", lyrics) # replaces multiple newlines by a single newline\n",
    "        lyrics = re.sub(\"\\{\\}\\[\\]\\*\\&\", \"\", lyrics)\n",
    "        for nickname in nicknames[dictio['artist']]: # replaces artists' nicknames with 'own_name'\n",
    "            lyrics = re.sub(nickname,\"own_name\",lyrics)\n",
    "            lyrics = re.sub(nickname.lower(),\"own_name\",lyrics)\n",
    "            lyrics = re.sub(nickname.upper(),\"own_name\",lyrics)\n",
    "        \n",
    "        lyrics = re.sub(\" .*?own_name.* \",\" own_name \",lyrics)\n",
    "       \n",
    "        dictio['shape_repr'] = create_shape_representation(lyrics)\n",
    "        lyrics = re.sub(\"\\.([1-9])\",r'\\1',lyrics) # convert .9 to 9\n",
    "        dictio['pos_repr'] = create_POS_representation(lyrics)\n",
    "        #lyrics = re.sub(\" 911\", \" 9 1 1\",lyrics)\n",
    "        #lyrics = re.sub(\"19([0-9]{2})\",r'19 \\1',lyrics)\n",
    "        #lyrics = re.sub(\"([0-9]+)\",number_to_word,lyrics) # convert numbers to words e.g. 50 to fifty\n",
    "        dictio['word_count'] = get_word_count(lyrics)\n",
    "        dictio['sentence_count'] = get_sentence_count(lyrics)\n",
    "        dictio['avg_word_length'] = get_avg_word_length(lyrics)\n",
    "        dictio['unique_word_ratio'] = get_unique_word_ratio(lyrics)\n",
    "        dictio['repeated_sentence_count_ratio'], dictio['repeated_sentence_ratio'] = get_repeated_sentence_ratios(lyrics)\n",
    "        #dictio['alliter_repr'] = create_alliteration_representation(lyrics)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #lyrics = re.sub(\" [\\'\\\"\\*\\’\\:\\;\\(\\)]\",\" \",lyrics) # removes specific punctuation after a space\n",
    "        #lyrics = re.sub(\"[\\'\\\"\\*\\’\\:\\;\\(\\)]([ \\n])\",r'\\1',lyrics) # removes specific punctuation before a space\n",
    "        #lyrics = re.sub(\"([\\.\\,\\!\\?]) \", r' \\1 ', lyrics) # adds space between word and punct if last character of word is punct\n",
    "        #lyrics = re.sub(\"([\\.\\,\\!\\?])\\n\", r' \\1\\n', lyrics) # adds space between word and punct if last character of word is punct\n",
    "        #lyrics.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        \n",
    "        dictio['lyrics'] = lyrics\n",
    "        \n",
    "        dictio['syllab_repr'] = create_syllable_representation(lyrics)\n",
    "        dictio['length_repr'] = create_length_representation(lyrics)\n",
    "        dictio['punctC_repr'] = create_punctC_representation(lyrics)\n",
    "        dictio['vowel_repr'] = create_vowel_representation(lyrics)\n",
    "        dictio['syllab_repr'] = create_syllable_representation(lyrics)\n",
    "        dictio['metaphone_repr'] = create_metaphone_representation(lyrics)\n",
    "        dictio['soundex_repr'] = create_soundex_representation(lyrics)\n",
    "        dictio['phonetic_repr'] = create_phonetic_representation(lyrics)\n",
    "        lyrics = re.sub(\"own_name\",\"John\", lyrics) # convert own_name to John for better NER_tagging\n",
    "        #dictio['ner_repr'] = create_NER_representation(lyrics,nlp)\n",
    "        \n",
    "        new_data.append(dictio)\n",
    "        \n",
    "        # to track where to program is while running\n",
    "        i += 1 \n",
    "        if i % 100 == 0:\n",
    "            print(i,end=' ')\n",
    "   # all_lyrics = [dictio['lyrics'].split() for dictio in new_data]\n",
    "    #c_all_words = Counter([word for lyrics in all_lyrics for word in lyrics])\n",
    "    \n",
    "    #for dictio in new_data:\n",
    "    #    dictio['frequency_repr'] = create_frequency_representation(dictio['lyrics'],c_all_words)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(\".*own_name.* \",\" own_name \",\" own_nametradameus \")\n",
    "re.sub(\"19([0-9]{2})\",r'19 \\1',\"199666\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist_list(data_set):\n",
    "    return [dictio['artist'] for dictio in data_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_raw_data(path):\n",
    "    songs_per_artist = []\n",
    "    for filename in os.listdir(path):\n",
    "        if filename[-4:] == \".csv\":\n",
    "            if 'dev' not in filename and 'train' not in filename and 'test' not in filename:\n",
    "                print(filename)\n",
    "                songs_per_artist.append(pd.read_csv(path+filename))\n",
    "    df = pd.concat(songs_per_artist, ignore_index = True)\n",
    "    data = []\n",
    "    for i,row in df.iterrows():\n",
    "        data.append({\"song_title\":row[\"song_title\"],\"artist\":row['artist'],\"lyrics\":row['lyrics'],\"featuring\":row['featuring']})\n",
    "    print(get_artist_list(data)[:10])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_one_csv_file(path):\n",
    "    df = pd.read_csv(path)\n",
    "    data = []\n",
    "    for i,row in df.iterrows():\n",
    "        data.append({\"song_title\":row[\"song_title\"],\"artist\":row['artist'],\"lyrics\":row['lyrics'],\"featuring\":row['featuring']})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_x_y_including_verses(data):\n",
    "    nicknames = get_nicknames()\n",
    "    new_data = []\n",
    "    for dictio in data:\n",
    "        #print(dictio['song_title'])\n",
    "        if isinstance(dictio['featuring'],float): # nan is a float, thus if no featuring artists it's a flaot\n",
    "            dictio['type'] = 'song'\n",
    "            new_data.append(dictio)\n",
    "        else:\n",
    "            #print(dictio.keys())\n",
    "            lyrics = dictio['lyrics']\n",
    "            lyrics = re.sub(\"\\n\",\"___\",lyrics)\n",
    "            verses = re.findall(\"\\[.+?\\].+?\\[\",lyrics,overlapped=True)\n",
    "            verses = [re.sub(\"___\",\"\\n\",verse) for verse in verses]\n",
    "            verses = [re.sub(\"\\n+\\[\",\"\",verse) for verse in verses]\n",
    "            combined_verses = []\n",
    "            for verse in verses:\n",
    "                header = re.findall(\"\\[.+?\\]\",verse) # header of a verse, as in [..]\n",
    "                if header != []:\n",
    "                    header = header[0].lower()\n",
    "                    header = header.split(':')\n",
    "                    if len(header) > 1:\n",
    "                        header = header[1].strip()[:-1]\n",
    "                    for nickname in nicknames[dictio['artist']]:\n",
    "                        if header == nickname.lower():\n",
    "                            verse = re.sub(\"\\[.+?\\]\",\"\",verse)\n",
    "                            combined_verses.append(verse)\n",
    "                            break\n",
    "            combined_verses = \"\\n\".join(combined_verses)\n",
    "            if len(combined_verses.split()) > 20:\n",
    "                dictio['lyrics'] = combined_verses\n",
    "                dictio['type'] = 'verses'\n",
    "                new_data.append(dictio)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_verse_classification(data):\n",
    "    \n",
    "    \"\"\" Converts instances of songs to instances of verses \"\"\"\n",
    "    \n",
    "    nicknames = get_nicknames()\n",
    "    new_data = []\n",
    "    all_verses = []\n",
    "    for dictio in data:\n",
    "        artist = dictio['artist']\n",
    "        lyrics = dictio['lyrics']\n",
    "        lyrics = re.sub(\"\\n\",\"___\",lyrics) # replace by ___ to preserse the location of the newline\n",
    "        verses = re.findall(\"\\[.+?\\].+?\\[\",lyrics,overlapped=True) # [...] indicates the start of a new verse\n",
    "        verses = [re.sub(\"___\",\"\\n\",verse) for verse in verses] # reinsert the newlines\n",
    "        verses = [re.sub(\"\\n+\\[\",\"\",verse) for verse in verses] # remove a remaining [\n",
    "        for verse in verses:\n",
    "            #print(\"\\n\\n\",verse)\n",
    "            if isinstance(dictio['featuring'],float): # if the entire song is by the same artist, simply add the verse to the data\n",
    "                verse = re.sub(\"\\[.+?\\]\",\"\",verse)\n",
    "                if len(verse.split()) > 20:\n",
    "                    new_dictio = dictio.copy()\n",
    "                    new_dictio['lyrics'] = verse.strip()\n",
    "                    #print(\"\\n\\n\",new_dictio['lyrics'],\"\\n\\n\")\n",
    "                    if new_dictio not in new_data:\n",
    "                        #print(\"appends verse\")\n",
    "                        new_data.append(new_dictio)\n",
    "                        all_verses.append(verse.strip())\n",
    "            else: # if the song in by multiple artists, check the artist of each verse\n",
    "                header = re.findall(\"\\[.+?\\]\",verse) # header of a verse, as in [..]\n",
    "                if header != []:\n",
    "                    header = header[0].lower()\n",
    "                    header = header.split(':')\n",
    "                    if len(header) > 1:\n",
    "                        header = header[1].strip()[:-1]\n",
    "                    for nickname in nicknames[dictio['artist']]:\n",
    "                        if header == nickname.lower():\n",
    "                            verse = re.sub(\"\\[.+?\\]\",\"\",verse)\n",
    "                            if len(verse.split()) > 20:\n",
    "                                new_dictio = dictio.copy()\n",
    "                                new_dictio['lyrics'] = verse.strip()\n",
    "                                print(\"\\n\\n\",new_dictio['lyrics'])\n",
    "                                if new_dictio not in new_data:\n",
    "                                    new_data.append(new_dictio)\n",
    "                                    all_verses.append(verse.strip())\n",
    "    song_titles = [dictio['song_title'] for dictio in new_data]\n",
    "    lyrics = [dictio['lyrics'] for dictio in new_data]\n",
    "    #for l in all_verses:\n",
    "     #   print(l,\"\\n\\n\")\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath = \"../lyrics/CADS/jayz&kanye/\"\n",
    "outpath = \"../lyrics/CADS/jayz&kanye/jayz&kanye\"\n",
    "data = import_raw_data(inpath)\n",
    "splitted_data = split_train_dev_test(data,True)\n",
    "datas = [('train',splitted_data[0][1] + splitted_data[1][1] + splitted_data[2][1])] # combine train dev and test\n",
    "datas = [(data_type,convert_to_verse_classification(data)) for data_type, data in datas[0:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_verse_classification_duo_artist(data):\n",
    "    \n",
    "    \"\"\" Convert to verse classification in a duo artist songs in which artist is set as e.g.: Jay-Z & Kanye West\"\"\"\n",
    "    \n",
    "    nicknames = get_nicknames()\n",
    "    artist1, artist2 = data[0]['artist'].split('&')[0].strip(), data[0]['artist'].split('&')[1].strip()\n",
    "    new_data = []\n",
    "    for dictio in data:\n",
    "        del dictio['featuring']\n",
    "        lyrics = dictio['lyrics']\n",
    "        lyrics = re.sub(\"\\n\",\"___\",lyrics)\n",
    "        verses = re.findall(\"\\[.+?\\].+?\\[\",lyrics,overlapped=True)\n",
    "        verses = [re.sub(\"___\",\"\\n\",verse) for verse in verses]\n",
    "        verses = [re.sub(\"\\n+\\[\",\"\",verse) for verse in verses]\n",
    "        for verse in verses:\n",
    "            y_verse = \"OTHER ARTIST\" # in case more artists particiate than artist1 and artist2\n",
    "            header = re.findall(\"\\[.+?\\]\",verse)[0].lower() # header of a verse, as in [..]\n",
    "            verse = re.sub(\"\\[.+?\\]\",\"\",verse)\n",
    "            if header != []:\n",
    "                header = header.split(':') # usually headers are like [verse1: artist]\n",
    "                if len(header) > 1:\n",
    "                    header = header[1].strip()[:-1]\n",
    "                elif type(header) == list: # this means the header didn't have a :\n",
    "                    header = header[0].split('-') # sometimes headers are like [verse1 - artist]\n",
    "                    if len(header) > 1:\n",
    "                        header = header[1].strip()[:-1]\n",
    "                for nickname in nicknames[artist1]:\n",
    "                    if header == nickname.lower():\n",
    "                        y_verse = artist1\n",
    "                for name in nicknames[artist2]: # set verse to artist2 of its not set to artist 1 or combined verse yet\n",
    "                    if name.lower() == header and y_verse != artist1 and y_verse != 'combined verse':\n",
    "                        y_verse = artist2\n",
    "                if y_verse == artist1 or y_verse == artist2:\n",
    "                    if len(verse.split()) >= 20:\n",
    "                        #print(\"found\")\n",
    "                        new_dictio = dictio.copy()\n",
    "                        new_dictio['artist'] = y_verse\n",
    "                        new_dictio['lyrics'] = verse\n",
    "                        new_data.append(new_dictio)\n",
    "            #print(y_verse)\n",
    "            \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(x,y):\n",
    "    new_x, new_y = [],[]\n",
    "    while len(x) > 0:\n",
    "        tempx = x.pop(0)\n",
    "        tempy = y.pop(0)\n",
    "        if tempx not in x:\n",
    "            new_x.append(tempx)\n",
    "            new_y.append(tempy)\n",
    "    return new_x, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffe_x_and_y(x,y):\n",
    "    \n",
    "    \"\"\" Returns a shuffled x and y \"\"\"\n",
    "    \n",
    "    x_and_y = [(x,y) for x,y in zip(x,y)] # combine x and y to keep the y related to the right x\n",
    "    random.seed(50)\n",
    "    random.shuffle(x_and_y)\n",
    "    new_x, new_y = [], []\n",
    "    for x,y in x_and_y:\n",
    "        new_x.append(x)\n",
    "        new_y.append(y)\n",
    "    return new_x, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_count(lyrics):\n",
    "    lyrics = re.sub(\"['’]\",\" \",lyrics) # to convert e.g. I'm into I m\n",
    "    lyrics = lyrics.translate(str.maketrans('','',string.punctuation))\n",
    "    return len(lyrics.split())\n",
    "    \n",
    "\n",
    "def get_sentence_count(lyrics):\n",
    "    return len(lyrics.split('\\n'))\n",
    "\n",
    "def get_avg_word_length(lyrics):\n",
    "    lyrics = lyrics.translate(str.maketrans('','',string.punctuation))\n",
    "    return round(sum([len(word) for word in lyrics.split()]) / len(lyrics.split()),2)\n",
    "    \n",
    "def get_exclam_mark_count(x):\n",
    "    return [lyrics.count('!') for lyrics in x]\n",
    "\n",
    "def get_question_mark_count(x):\n",
    "    return [lyrics.count('?') for lyrics in x]\n",
    "\n",
    "def get_comma_count(x):\n",
    "    return [lyrics.count(',')for lyrics in x]\n",
    "\n",
    "def get_comma_ratio(x):\n",
    "    return [round(lyrics.count(',') / len(lyrics.split('\\n')),2) for lyrics in x]\n",
    "\n",
    "def get_unique_word_ratio(lyrics):\n",
    "    lyrics = re.sub(\"['’]\",\" \",lyrics)\n",
    "    lyrics =lyrics.translate(str.maketrans('','',string.punctuation))\n",
    "    return round(len(set(lyrics.split())) / len(lyrics.split()),2)\n",
    "\n",
    "\n",
    "def get_repeated_sentence_ratios(lyrics):\n",
    "    repeated_sentence_count_ratios = [] # sum of sentences that are repeated / amount of sentences\n",
    "    repeated_sentence_ratios = [] # sum of different sentences that are repeated / amount of different sentences\n",
    "    sentence_counter = Counter(lyrics.split('\\n'))\n",
    "    total_sentences = len(lyrics.split('\\n'))\n",
    "    repeated_sentences_count = sum([instances for sentence,instances in sentence_counter.items()])\n",
    "    repeated_sentences = sum([1 for sentence,instances in sentence_counter.items()])\n",
    "    return round(repeated_sentences_count/total_sentences,2), round(repeated_sentences/len(sentence_counter),2)\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_dev_test(data,add_verses):\n",
    "    songs = []\n",
    "    verses = []\n",
    "    for dictio in data:\n",
    "        if isinstance(dictio['featuring'],float): # nan is a float, thus if no featuring artists it's a float\n",
    "            songs.append(dictio)\n",
    "        else:\n",
    "            verses.append(dictio)\n",
    "    random.seed(50)\n",
    "    random.shuffle(songs)\n",
    "    train = songs[:int(0.8*len(songs))]\n",
    "    print(Counter(get_artist_list(train)))\n",
    "    dev = songs[int(0.8*len(songs)):int(0.9*len(songs))]\n",
    "    test = songs[int(0.9*len(songs)):]\n",
    "    if add_verses == True:\n",
    "        train = train + verses\n",
    "        random.shuffle(train)\n",
    "    return [\"train\",train],[\"dev\",dev],[\"test\",test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_verses(data_set):\n",
    "    return [dictio for dictio in data_set if isinstance(dictio['featuring'],float)]\n",
    "\n",
    "def return_verses(data_set):\n",
    "    return [dictio for dictio in data_set if not isinstance(dictio['featuring'],float)]\n",
    "\n",
    "def balance_data_set(data_set_l, data_set_s,mc_artist_l,mc_artist_s):    \n",
    "        \n",
    "    #y_data_set_l = get_artist_list(data_set_l)\n",
    "    #y_data_set_l = get_artist_list(data_set_to_sort_by)\n",
    "    y_data_set_s = Counter(get_artist_list(data_set_s))\n",
    "    \n",
    "    #mc_artist_l = Counter(y_data_set_l).most_common()\n",
    "    #mc_artist_s = Counter(y_data_set_s).most_common()\n",
    "    new_data_set_l = []\n",
    "    for l,s in zip(mc_artist_l,mc_artist_s):\n",
    "        artist_l = l[0]\n",
    "        songs_s = y_data_set_s[s[0]]\n",
    "        new_data_set_l += [dictio for dictio in data_set_l if dictio['artist'] == artist_l][:songs_s]\n",
    "    \n",
    "    print(Counter(get_artist_list(new_data_set_l)))\n",
    "    print(Counter(get_artist_list(data_set_s)))\n",
    "    return new_data_set_l\n",
    "\n",
    "\n",
    "\"\"\"data_set_s = import_raw_data(\"../lyrics/diverse/\")\n",
    "data_set_l = import_raw_data(\"../lyrics/afro_males/\")\n",
    "data_set_s = remove_verses(data_set_s)\n",
    "data_set_l = remove_verses(data_set_l)\n",
    "\n",
    "\n",
    "\n",
    "outpath = \"../lyrics/experiments/AAMDS_to_DADS\"\n",
    "data = balance_data_set(data_set_l,data_set_s)\n",
    "datas = split_train_dev_test(data,False)\n",
    "datas = [(data_type,form_x_y_including_verses(data)) for data_type, data in datas]\n",
    "datas = [(data_type,preprocess_lyrics(data)) for data_type, data in datas]\n",
    "for data_type, data in datas:\n",
    "    write_to_csv(data,outpath,data_type)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(data, path, data_type):\n",
    "    keys = list(data[0].keys())\n",
    "    with open(path + \"_\" + data_type + \".csv\", 'w') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_for_glad(train_data,test_data,path_to_glad_folder):\n",
    "    \"\"\"artists = list(set([dictio['artist'] for dictio in train_data]))\n",
    "    artist1 = [dictio['lyrics'] for dictio in train_data if dictio['artist'] == artists[0]]\n",
    "    artist2 = [dictio['lyrics'] for dictio in train_data if dictio['artist'] == artists[1]]\n",
    "    random.seed(30)\n",
    "    \n",
    "    artist_names = list(set([dictio['artist'] for dictio in train_data]))\n",
    "    data_per_artist = []\n",
    "    for name in artist_names:\n",
    "        data_per_artist.append((name,[dictio['lyrics'] for dictio in train_data if dictio['artist'] == name]))\"\"\"\n",
    "    \n",
    "    song_amount_per_artist = Counter([dictio['artist'] for dictio in train_data])\n",
    "    song_amount_per_artist = song_amount_per_artist.most_common()\n",
    "    print(song_amount_per_artist)\n",
    "    known_data = [] # list with each item a list of the song dictios of one specific artist\n",
    "    unknown_data = [] # list with each item a list of the song dictios of two artists\n",
    "    for i in range(0,len(song_amount_per_artist),2):\n",
    "        artist1 = song_amount_per_artist[i][0]\n",
    "        artist2 = song_amount_per_artist[i+1][0]\n",
    "        known_data_artist1 = [dictio for dictio in train_data if dictio['artist'] == artist1]\n",
    "        known_data_artist2 = [dictio for dictio in train_data if dictio['artist'] == artist2]\n",
    "        known_data.append(known_data_artist1)\n",
    "        known_data.append(known_data_artist2)\n",
    "        \n",
    "        # unknown data must be of two artists, to make sure there are matching and non matching cases\n",
    "        pair_unknown_data = [dictio for dictio in test_data if dictio['artist'] == artist1] + \\\n",
    "                            [dictio for dictio in test_data if dictio['artist'] == artist2]\n",
    "        random.shuffle(pair_unknown_data) # to be unknown lyrics must be shuffled to have random order\n",
    "        \n",
    "        # make sure the amount of unknown songs is in proportion to the amount of known songs\n",
    "        limit = int(len(known_data_artist1) / (len(known_data_artist1) + len(known_data_artist2)) * \\\n",
    "                    len(pair_unknown_data))\n",
    "        unknown1 = pair_unknown_data[:limit]\n",
    "        unknown2 = pair_unknown_data[limit:]\n",
    "        \n",
    "        unknown_data.append(unknown1)\n",
    "        unknown_data.append(unknown2)\n",
    "        \n",
    "    #artists = [(artists[0],artist1), (artists[1],artist2)] # index 0 refers to artists1 index 1 to artists2\n",
    "    train_docs_per_unknown = int(len(train_data)/len(test_data))\n",
    "    print(train_docs_per_unknown)\n",
    "    \n",
    "    random.shuffle(test_data)\n",
    "    problem_i = 0\n",
    "    if not os.path.exists(path_to_glad_folder):\n",
    "        os.mkdir(path_to_glad_folder)\n",
    "    \n",
    "    if not os.path.exists(path_to_glad_folder +\"/truth\"):\n",
    "        os.mkdir(path_to_glad_folder + \"/truth\")\n",
    "    with open(path_to_glad_folder + \"truth/truth.txt\", 'w') as truthtxt:\n",
    "        for known_set, unknown_set in zip(known_data, unknown_data):\n",
    "            train_docs_per_unknown = int(len(known_set)/len(unknown_set))\n",
    "            start_i = 0\n",
    "            end_i = start_i + train_docs_per_unknown\n",
    "            artist_name = known_set[0]['artist']\n",
    "            lyrics_list = [dictio['lyrics'] for dictio in known_set]\n",
    "            print(len(lyrics_list))\n",
    "            while start_i < len(lyrics_list) - train_docs_per_unknown and len(unknown_set) > 0:\n",
    "                problem_i += 1\n",
    "                problem_id = ('000' + str(problem_i))[-4:]\n",
    "                if not os.path.exists(path_to_glad_folder + problem_id):\n",
    "                    os.mkdir(path_to_glad_folder + problem_id)\n",
    "                train_docs = lyrics_list[start_i:end_i]\n",
    "                #print(len(train_docs))\n",
    "                doc_i = 1\n",
    "                doc_id = ('00'+ str(doc_i))[-2:]\n",
    "                for lyrics in train_docs[:1]:\n",
    "                    doc_id = ('00'+ str(doc_i))[-2:]\n",
    "                    with open(path_to_glad_folder + problem_id + '/' + problem_id + '_known0' + str(doc_id)+ '.txt','w') as knownfile:\n",
    "                        knownfile.write(lyrics)\n",
    "                        doc_i += 1\n",
    "                with open(path_to_glad_folder + problem_id + '/unknown.txt','w') as unknownfile:\n",
    "                    test_instance = unknown_set.pop(0)\n",
    "                    unknown_verse = test_instance['lyrics']\n",
    "                    unknown_artist = test_instance['artist']\n",
    "                    unknownfile.write(unknown_verse)\n",
    "                    if unknown_artist == artist_name:\n",
    "                        truthtxt.write(problem_id + ' Y\\n')\n",
    "                    else:\n",
    "                        truthtxt.write(problem_id + ' N\\n')\n",
    "                start_i += train_docs_per_unknown\n",
    "                end_i = start_i + train_docs_per_unknown\n",
    "                    #print(start_i, len(lyrics_list),len(test_data))\n",
    "                 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath = \"../lyrics/gender/female/\"\n",
    "data_female = import_raw_data(inpath)\n",
    "for dictio in data_female:\n",
    "    dictio['gender'] = 'female'\n",
    "datas_female = split_train_dev_test(data_female)\n",
    "\n",
    "\n",
    "\n",
    "data_male = import_raw_data(\"../lyrics/gender/male/\")\n",
    "for dictio in data_male:\n",
    "    dictio['gender'] = 'male'\n",
    "    \n",
    "verses_male = return_verses(data_male)\n",
    "verses_female = return_verses(data_female)    \n",
    "verses_male = form_x_y_including_verses(verses_male)\n",
    "verses_female = form_x_y_including_verses(verses_female)\n",
    "#added_verses_male = balance_data_set(verses_male,verses_female,data_male)\n",
    "\n",
    "datas_male = split_train_dev_test(data_male,False)\n",
    "\n",
    "mc_data_female = Counter(get_artist_list(datas_female[0][1])).most_common()\n",
    "mc_data_male = Counter(get_artist_list(datas_male[0][1])).most_common()\n",
    "\n",
    "\n",
    "added_verses_male = balance_data_set(verses_male,verses_female,mc_data_male,mc_data_female)\n",
    "print(\"!!!!!!!!!!!!!!!!!!!!!\",Counter(get_artist_list(added_verses_male)))\n",
    "print(\"!!!!!!!!!!!!!!!!!!!!!\",Counter(get_artist_list(verses_female)))\n",
    "datas = []\n",
    "for data_female, data_male in zip(datas_female,datas_male):\n",
    "    #print(data_female[1])\n",
    "    male_balanced_to_female = balance_data_set(data_male[1], data_female[1],mc_data_male,mc_data_female)\n",
    "    datas.append([data_female[0],male_balanced_to_female+data_female[1]])\n",
    "\n",
    "datas = [[data_type,form_x_y_including_verses(data)] for data_type, data in datas]\n",
    "#datas[0][1] += added_verses_male + verses_female\n",
    "\n",
    "\n",
    "datas = [(data_type,preprocess_lyrics(data)) for data_type, data in datas]\n",
    "for data_type, data in datas:\n",
    "    write_to_csv(data,'../lyrics/gender/GBDS_no_verses',data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inpath = \"../lyrics/afro_males/\"\n",
    "data = import_raw_data(inpath)\n",
    "datas = split_train_dev_test(data,True)\n",
    "datas = [form_x_y_including_verses(data) for data_type,data in datas]\n",
    "songs_incl_verses = [song['artist'] for song in datas[0]]\n",
    "data = import_raw_data(inpath)\n",
    "datas = split_train_dev_test(data,False)\n",
    "songs_train = [song['artist'] for song in datas[0][1]]\n",
    "songs_dev = [song['artist'] for song in datas[1][1]]\n",
    "songs_test = [song['artist'] for song in datas[2][1]]\n",
    "c_total_songs_per_artist = Counter(songs_train+songs_dev+songs_test)\n",
    "total_songs_per_artist = c_total_songs_per_artist.most_common()\n",
    "print(total_songs_per_artist)\n",
    "c_total = Counter(songs_incl_verses)\n",
    "c_dev = Counter(songs_dev)\n",
    "c_test = Counter(songs_test)\n",
    "c_train = Counter(songs_train)\n",
    "train_total, verse_total, dev_total, test_total = 0,0,0,0\n",
    "print(c_total)\n",
    "for artist, x in total_songs_per_artist:\n",
    "    print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(artist,c_total_songs_per_artist[artist],c_train[artist],c_dev[artist],c_test[artist],c_total[artist]-c_train[artist]))\n",
    "print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(\"TOTAL\",len(songs_train)+len(songs_dev)+len(songs_test),len(songs_train),len(songs_dev), len(songs_test),len(songs_incl_verses)-len(songs_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jayz.csv\n",
      "2pac.csv\n",
      "snoop.csv\n",
      "lil_wayne.csv\n",
      "nas.csv\n",
      "future.csv\n",
      "ice_cube.csv\n",
      "50cent.csv\n",
      "['JAY-Z', 'JAY-Z', 'JAY-Z', 'JAY-Z', 'JAY-Z', 'JAY-Z', 'JAY-Z', 'JAY-Z', 'JAY-Z', 'JAY-Z']\n",
      "test ['JAY-Z', 'JAY-Z', 'JAY-Z', 'JAY-Z', 'JAY-Z', 'JAY-Z', 'JAY-Z', 'JAY-Z', 'JAY-Z', 'JAY-Z']\n",
      "Counter({'Lil Wayne': 269, 'Future': 182, '50 Cent': 137, 'Snoop Dogg': 129, 'Nas': 121, 'Ice Cube': 109, 'JAY-Z': 95, '2Pac': 80})\n",
      "train Counter({'Lil Wayne': 269, 'Future': 182, '50 Cent': 137, 'Snoop Dogg': 129, 'Nas': 121, 'Ice Cube': 109, 'JAY-Z': 95, '2Pac': 80})\n",
      "dev Counter({'Lil Wayne': 38, 'Future': 26, 'Ice Cube': 16, 'Nas': 14, '50 Cent': 13, 'JAY-Z': 13, 'Snoop Dogg': 12, '2Pac': 8})\n",
      "test Counter({'Lil Wayne': 31, 'Future': 27, '50 Cent': 18, 'Snoop Dogg': 16, 'JAY-Z': 13, 'Ice Cube': 13, '2Pac': 12, 'Nas': 11})\n"
     ]
    }
   ],
   "source": [
    "# run this cell to create the train dev and test set based on songs\n",
    "\n",
    "inpath = \"../lyrics/afro_males/\"\n",
    "outpath = \"../lyrics/diverse/diverse_artist_no_punct\"\n",
    "data = import_raw_data(inpath)\n",
    "print(data_type,get_artist_list(data)[:10])\n",
    "datas = split_train_dev_test(data,False)\n",
    "for data_type, data in datas:\n",
    "    print(data_type,Counter(get_artist_list(data)))\n",
    "datas = [(data_type,form_x_y_including_verses(data)) for data_type, data in datas]\n",
    "#datas = [(data_type,preprocess_lyrics(data)) for data_type, data in datas]\n",
    "#splitted_data = split_train_dev_test(data,False)\n",
    "#for data_type, data in datas:\n",
    "    #write_to_csv(data,outpath,data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath = \"../lyrics_old/afro_males/\"\n",
    "outpath = \"../lyrics_old/experiments/AAMDS_no_verses_with_digits\"\n",
    "#inpath = \"../lyrics/diverse/\"\n",
    "#outpath = \"../lyrics/experiments/DADS_TRY_wv_nopunct\"\n",
    "data = import_raw_data(inpath)\n",
    "#print(Counter(get_artist_list(data)))\n",
    "datas = split_train_dev_test(data,False)\n",
    "datas = [(data_type,form_x_y_including_verses(data)) for data_type, data in datas]\n",
    "datas = [(data_type,preprocess_lyrics(data)) for data_type, data in datas]\n",
    "for data_type, data in datas:\n",
    "    print(data_type,Counter(get_artist_list(data)))\n",
    "#for data_type, data in datas:\n",
    "    #write_to_csv(data,outpath,data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to create the train data with added verses\n",
    "\n",
    "inpath = \"../lyrics_old/afro_males/\"\n",
    "outpath = \"../lyrics_old/afro_males/DADS_with_verses\"\n",
    "data = import_raw_data(inpath)\n",
    "datas = split_train_dev_test(data,False)\n",
    "#for data_type, data in datas:\n",
    "#    print(data_type,Counter(get_artist_list(data)))\n",
    "datas = [(data_type,form_x_y_including_verses(data)) for data_type, data in datas]\n",
    "datas = [(data_type,preprocess_lyrics(data)) for data_type, data in datas]\n",
    "for data_type, data in datas:\n",
    "    print(data_type,Counter(get_artist_list(data)))\n",
    "#for data_type, data in datas:\n",
    "    #write_to_csv(data,outpath,data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath = \"../lyrics/marley&nas/\"\n",
    "outpath = \"../lyrics/marley&nas/marley&nas\"\n",
    "data = import_raw_data(inpath)\n",
    "data = form_x_y_including_verses(data)\n",
    "data = preprocess_lyrics(data)\n",
    "splitted_data = split_train_dev_test(data,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath = \"../lyrics/marley&nas/\"\n",
    "outpath = \"../lyrics/marley&nas/marley&nas\"\n",
    "data = import_raw_data(inpath)\n",
    "splitted_data = split_train_dev_test(data,True)\n",
    "datas = [('train',splitted_data[0][1] + splitted_data[1][1] + splitted_data[2][1])] # combine train dev and test\n",
    "datas = [(data_type,convert_to_verse_classification(data)) for data_type, data in datas]\n",
    "#datas = [(data_type,preprocess_lyrics(data)) for data_type, data in datas]\n",
    "print(Counter(get_artist_list(datas[0][1])))\n",
    "#splitted_data = split_train_dev_test(data,False)\n",
    "for data_type, data in datas:\n",
    "    write_to_csv(data,outpath,data_type)\n",
    "    \n",
    "# create test data for duo artist classification on Damian Marley and Nas    \n",
    "data = import_one_csv_file(\"../lyrics/marley&nas_combined/marley&nas.csv\")  \n",
    "data = convert_to_verse_classification_duo_artist(data)\n",
    "data = preprocess_lyrics(data)\n",
    "write_to_csv(data,\"../lyrics/marley&nas_combined/marely&nas\",\"test\")\n",
    "print(Counter(get_artist_list(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath = \"../lyrics/CADS/jayz&kanye/\"\n",
    "outpath = \"../lyrics/CADS/jayz&kanye/jayz&kanye\"\n",
    "data = import_raw_data(inpath)\n",
    "splitted_data = split_train_dev_test(data,True)\n",
    "datas = [('train',splitted_data[0][1] + splitted_data[1][1] + splitted_data[2][1])] # combine train dev and test\n",
    "#datas = [(data_type,convert_to_verse_classification(data)) for data_type, data in datas]\n",
    "datas = [(data_type,form_x_y_including_verses(data)) for data_type, data in datas]\n",
    "datas = [(data_type,preprocess_lyrics(data)) for data_type, data in datas]\n",
    "print(Counter(get_artist_list(datas[0][1])))\n",
    "#splitted_data = split_train_dev_test(data,False)\n",
    "for data_type, data in datas:\n",
    "    write_to_csv(data,outpath,data_type)\n",
    "    \n",
    "# create test data for duo artist classification on Damian Marley and Nas    \n",
    "data = import_one_csv_file(\"../lyrics/CADS/jayz&kanye_combined/jayz&kanye.csv\")  \n",
    "data = convert_to_verse_classification_duo_artist(data)\n",
    "data = preprocess_lyrics(data)\n",
    "write_to_csv(data,\"../lyrics/CADS/jayz&kanye_combined/jayz&kanye\",\"test\")\n",
    "print(Counter(get_artist_list(data))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "inpath = \"../lyrics/CADS/marley&nas/\"\n",
    "outpath = \"../lyrics/CADS/marley&nas/marley&nas\"\n",
    "data = import_raw_data(inpath)\n",
    "splitted_data = split_train_dev_test(data,True)\n",
    "datas = [('train',splitted_data[0][1] + splitted_data[1][1] + splitted_data[2][1])] # combine train dev and test\n",
    "#datas = [(data_type,convert_to_verse_classification(data)) for data_type, data in datas]\n",
    "datas = [(data_type,form_x_y_including_verses(data)) for data_type, data in datas]\n",
    "datas = [(data_type,preprocess_lyrics(data)) for data_type, data in datas]\n",
    "print(Counter(get_artist_list(datas[0][1])))\n",
    "#splitted_data = split_train_dev_test(data,False)\n",
    "for data_type, data in datas:\n",
    "    write_to_csv(data,outpath,data_type)\n",
    "    \n",
    "# create test data for duo artist classification on Damian Marley and Nas    \n",
    "data = import_one_csv_file(\"../lyrics/CADS/marley&nas_combined/marley&nas.csv\")  \n",
    "data = convert_to_verse_classification_duo_artist(data)\n",
    "data = preprocess_lyrics(data)\n",
    "write_to_csv(data,\"../lyrics/CADS/marley&nas_combined/marley&nas\",\"test\")\n",
    "print(Counter(get_artist_list(data))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run this cell to create the test data for glad verse verification of Damian Marley & Nas\n",
    "\n",
    "inpath = \"../lyrics/marley&nas/\"\n",
    "known_data = import_raw_data(inpath)\n",
    "known_data = convert_to_verse_classification(known_data)\n",
    "known_data = preprocess_lyrics(known_data)\n",
    "#splitted_data = split_train_dev_test(data,True)\n",
    "#training_data = preprocess_lyrics(training_data)\n",
    "\n",
    "unknown_data = import_one_csv_file(\"../lyrics/marley&nas_combined/marley&nas.csv\")\n",
    "unknown_data = convert_to_verse_classification_duo_artist(unknown_data)\n",
    "unknown_data = preprocess_lyrics(unknown_data)\n",
    "write_for_glad(known_data,unknown_data,\"../lyrics/glad/test_data/marley&nas_single/\")\n",
    "#test_data = preprocess_lyrics(test_data)\n",
    "#print(\"\\n\\n\",len(training_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to create the train data for glad verse classification\n",
    "\n",
    "inpath = \"../lyrics/glad/raw_train_data/\"\n",
    "outpath = \"../lyrics/glad/train_data_single/\"\n",
    "data = import_raw_data(inpath)\n",
    "data = convert_to_verse_classification(data)\n",
    "data = preprocess_lyrics(data)\n",
    "splitted_data = split_train_dev_test(data,True)\n",
    "#training_data = preprocess_lyrics(training_data)\n",
    "write_for_glad(splitted_data[0][1],splitted_data[1][1] + splitted_data[2][1],outpath)\n",
    "#test_data = preprocess_lyrics(test_data)\n",
    "#print(\"\\n\\n\",len(training_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath = \"../lyrics/jayz&kanye/\"\n",
    "known_data = import_raw_data(inpath)\n",
    "known_data = convert_to_verse_classification(known_data)\n",
    "known_data = preprocess_lyrics(known_data)\n",
    "#splitted_data = split_train_dev_test(data,True)\n",
    "#training_data = preprocess_lyrics(training_data)\n",
    "\n",
    "unknown_data = import_one_csv_file(\"../lyrics/marley&nas_combined/jayz&kanye.csv\")\n",
    "unknown_data = convert_to_verse_classification_duo_artist(unknown_data)\n",
    "unknown_data = preprocess_lyrics(unknown_data)\n",
    "write_for_glad(known_data,unknown_data,\"../lyrics/glad/test_data/jayz&kanye_unpreproccesed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to create the test data for glad verse verification of Damian Marley & Nas\n",
    "\n",
    "inpath = \"../lyrics/marley&nas/\"\n",
    "known_data = import_raw_data(inpath)\n",
    "known_data = convert_to_verse_classification(known_data)\n",
    "known_data = preprocess_lyrics(known_data)\n",
    "splitted_data = split_train_dev_test(known_data,True)\n",
    "#training_data = preprocess_lyrics(training_data)\n",
    "\n",
    "#unknown_data = import_one_csv_file(\"../lyrics/marley&nas_combined/marley&nas.csv\")\n",
    "#unknown_data = convert_to_verse_classification_duo_artist(unknown_data)\n",
    "#unknown_data = preprocess_lyrics(unknown_data)\n",
    "write_for_glad(splitted_data[0][1],splitted_data[1][1] + splitted_data[2][1],\"../lyrics/glad/train_data_marley&nas/\")\n",
    "#test_data = preprocess_lyrics(test_data)\n",
    "#print(\"\\n\\n\",len(training_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
